# UML Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹: ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°

## Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ 4: ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ² (BERT)

### 1. Use Case Diagram (Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)

```mermaid
graph TB
    subgraph "Actors"
        MLService[ğŸ¤– ML Service]
        Doctor[ğŸ‘¨â€âš•ï¸ Ğ’Ñ€Ğ°Ñ‡]
        MLEngineer[ğŸ‘¨â€ğŸ’» ML Engineer]
    end
    
    subgraph "Use Cases"
        Tokenize[Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ²]
        BERTAnalysis[BERT-Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ²]
        Validate[Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ¹ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸]
        FineTune[Fine-tuning BERT Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸]
    end
    
    MLService --> Tokenize
    MLService --> BERTAnalysis
    Doctor --> Validate
    MLEngineer --> FineTune
    Validate -.->|extends| BERTAnalysis
    
    style MLService fill:#67c23a,stroke:#4a9428,stroke-width:2px
    style Doctor fill:#67c23a,stroke:#4a9428,stroke-width:2px
    style MLEngineer fill:#67c23a,stroke:#4a9428,stroke-width:2px
    style Tokenize fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style BERTAnalysis fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style Validate fill:#9966ff,stroke:#7744cc,stroke-width:2px,color:#fff
    style FineTune fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
```

**ĞĞºÑ‚Ñ‘Ñ€Ñ‹:**
- **ML Service** (ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°)
- **Ğ’Ñ€Ğ°Ñ‡** (Doctor)
- **ML Engineer** (Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ)

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**
1. **Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ²**
   - ĞŸĞµÑ€Ğ²Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ°ĞºÑ‚Ñ‘Ñ€: ML Service
   - ĞŸÑ€ĞµĞ´ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ: Ğ¢ĞµĞºÑÑ‚ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ² Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½
   - ĞŸĞ¾ÑÑ‚ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ: Ğ¢Ğ¾ĞºĞµĞ½Ñ‹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğ´Ğ»Ñ BERT
   
2. **BERT-Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ²**
   - ĞŸĞµÑ€Ğ²Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ°ĞºÑ‚Ñ‘Ñ€: ML Service
   - ĞŸÑ€ĞµĞ´ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ: Ğ¢Ğ¾ĞºĞµĞ½Ñ‹ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹
   - ĞŸĞ¾ÑÑ‚ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ: Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ñ‹
   
3. **Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ¹ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸**
   - ĞŸĞµÑ€Ğ²Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ°ĞºÑ‚Ñ‘Ñ€: Ğ’Ñ€Ğ°Ñ‡
   - Ğ¡Ğ²ÑĞ·ÑŒ: `<<extend>>` Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
   
4. **Fine-tuning BERT Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸**
   - ĞŸĞµÑ€Ğ²Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ°ĞºÑ‚Ñ‘Ñ€: ML Engineer
   - ĞŸÑ€ĞµĞ´ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ: ĞĞ¾Ğ²Ñ‹Ğµ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
   - ĞŸĞ¾ÑÑ‚ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ: ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°

**Ğ¡Ğ²ÑĞ·Ğ¸:**
- `<<include>>`: ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
- `<<extend>>`: Spell-check Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

---

### 2. Activity Diagram (Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ĞµĞ¹)

```mermaid
flowchart TD
    Start([ĞĞ°Ñ‡Ğ°Ğ»Ğ¾: Text from RabbitMQ])
    
    A[ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ symptom_text Ğ¸Ğ· ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ]
    B{Ğ¢ĞµĞºÑÑ‚ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼?}
    C[ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹ Google Translate API]
    D[ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ° lowercase, ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµÑ†ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²]
    E[ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾Ñ€Ñ„Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¸ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ²]
    F{Ğ¢ĞµÑ€Ğ¼Ğ¸Ğ½Ñ‹ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹?}
    G[ĞšĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğ¹ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ]
    H[Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· BERT Tokenizer]
    I[Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² CLS, SEP]
    J[Padding Ğ´Ğ¾ max_length=128]
    K[Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ attention_mask]
    L[ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² input_ids]
    
    M[BERT Encoding]
    N[Named Entity Recognition]
    O[ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ embeddings]
    P[ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ²]
    Q[Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… ÑÑƒÑ‰Ğ½Ğ¾ÑÑ‚ĞµĞ¹]
    R[ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²]
    S[Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Redis TTL=1h]
    T[ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ]
    End([ĞšĞ¾Ğ½ĞµÑ†])
    
    Start --> A
    A --> B
    B -->|ĞĞµÑ‚| C
    C --> D
    B -->|Ğ”Ğ°| D
    D --> E
    E --> F
    F -->|ĞĞµÑ‚| G
    G --> H
    F -->|Ğ”Ğ°| H
    H --> I
    I --> J
    J --> K
    K --> L
    
    L --> M
    L --> N
    M --> O
    N --> Q
    O --> P
    Q --> R
    P --> R
    R --> S
    S --> T
    T --> End
    
    style Start fill:#67c23a,stroke:#4a9428,stroke-width:3px
    style End fill:#f56c6c,stroke:#c94545,stroke-width:3px
    style B fill:#e6a23c,stroke:#b8821e,stroke-width:2px
    style F fill:#e6a23c,stroke:#b8821e,stroke-width:2px
    style H fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style M fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style S fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
```
    â•‘  TensorFlow Serving      â•‘  SpaCy Medical NER
    â•‘         â†“                â•‘          â†“
    â•‘ [ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ embeddings]   â•‘ [Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¾Ğ²]
    â•‘                          â•‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“ Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
[ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Dense Layer]
    â†“
[Softmax activation (Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸)]
    â†“
[Ğ¡Ğ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ¹ Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸Ğ¹]
    â†“
[Ğ Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¿-5 Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾Ğ·Ğ¾Ğ²]
    â†“
[Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ (LIME/SHAP)]
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â•‘ ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ â•‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â•‘                          â•‘
    â•‘ [Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Redis]     â•‘ [Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² PostgreSQL]
    â•‘  TTL = 1 Ñ‡Ğ°Ñ             â•‘  + Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ
    â•‘                          â•‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â†“
[ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ²Ñ€Ğ°Ñ‡Ñƒ]
    â†“
[ĞšĞ¾Ğ½ĞµÑ†]
```

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° BERT Ğ¸ NER
- Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸

---

### 3. Sequence Diagram (Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸)

**Ğ£Ñ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¸:**
- RabbitMQ
- TextAnalysisService
- TextPreprocessor
- BERTTokenizer
- TensorFlowServing
- BERTModel
- ClassificationHead
- DiseaseDatabase
- ExplainabilityService
- Redis
- PostgreSQL

```
RabbitMQ  TextService  Preprocessor  Tokenizer  TFServing  BERT  ClassHead  DiseaseDB  Explainer  Redis  PostgreSQL
   |          |            |            |          |         |       |         |          |        |        |
   |--msg---->|            |            |          |         |       |         |          |        |        |
   |{text}    |            |            |          |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--clean(text)---------->|          |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |      [lowercase, remove special chars]       |       |         |          |        |        |
   |          |      [spell check]     |          |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |<--cleaned_text---------|          |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--tokenize(cleaned_text)----------->|         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |            |     [convert to tokens]         |       |         |          |        |        |
   |          |            |     [add [CLS], [SEP]]          |       |         |          |        |        |
   |          |            |     [padding to 128]            |       |         |          |        |        |
   |          |            |     [create attention_mask]     |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |<--tokens-----------------|         |         |       |         |          |        |        |
   |          |  {input_ids, attention_mask}       |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--encode(tokens)-------------------->|        |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |            |            |     [gRPC call]    |       |         |          |        |        |
   |          |            |            |          |-------->|       |         |          |        |        |
   |          |            |            |          | forward_pass   |         |          |        |        |
   |          |            |            |          |<--------|       |         |          |        |        |
   |          |            |            |      [768-dim embeddings] |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |<--embeddings------------|          |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--classify(embeddings)-------------------------->|    |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |            |            |          |    [Dense(768 â†’ 256)]    |          |        |        |
   |          |            |            |          |    [ReLU]                |          |        |        |
   |          |            |            |          |    [Dropout(0.3)]        |          |        |        |
   |          |            |            |          |    [Dense(256 â†’ num_classes)]     |        |        |
   |          |            |            |          |    [Softmax]             |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |<--probabilities---------|          |         |<------|         |          |        |        |
   |          |  [0.45, 0.32, 0.15, ...]           |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--lookup_diseases(top_k=5)--------------------|------>|         |          |        |        |
   |          |            |            |          |         |       |  SELECT |          |        |        |
   |          |<--disease_names---------|          |         |       |<--------|          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--generate_explanation(text, probs)----------|-------|---------|--------->|        |        |
   |          |            |            |          |         |       |         |  SHAP   |        |        |
   |          |<--explanation_json------|          |         |       |         |<---------|        |        |
   |          |  {key_symptoms: [...], impact: [...]}        |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |            |   [Parallel save]     |         |       |         |          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--cache(results)------------------------------------------->|    |          |        |        |
   |          |            |            |          |         |       | SET     |          |        |        |
   |          |            |            |          |         |       |<--------|          |        |        |
   |          |            |            |          |         |       |         |          |        |        |
   |          |--save(results, explanation)------------------------------>|    |          |------->|        |
   |          |            |            |          |         |       |         |   INSERT |        |        |
   |          |            |            |          |         |       |         |          |<-------|        |
   |          |            |            |          |         |       |         |          |        |        |
   |<--ACK----|            |            |          |         |       |         |          |        |        |
```

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ pre-trained BERT Ñ fine-tuned classification head
- SHAP Ğ´Ğ»Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹
- ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

---

### 4. Class Diagram (Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° ĞºĞ»Ğ°ÑÑĞ¾Ğ²)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TextAnalysisService           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - preprocessor: TextPreprocessorâ”‚
â”‚ - tokenizer: BERTTokenizer      â”‚
â”‚ - bertClient: TensorFlowClient  â”‚
â”‚ - classifier: Classifier        â”‚
â”‚ - explainer: Explainability     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + analyzeSymptoms(text): Result â”‚
â”‚ + processMessage(msg): void     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ uses
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TextPreprocessor              â”‚         â”‚   BERTTokenizer             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - medicalDict: Dictionary       â”‚         â”‚ - vocab: Vocabulary         â”‚
â”‚ - translator: Translator        â”‚         â”‚ - maxLength: int = 128      â”‚
â”‚ - spellChecker: SpellChecker    â”‚         â”‚ - padToken: String = "[PAD]"â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + clean(text): String           â”‚         â”‚ + tokenize(text): Tokens    â”‚
â”‚ + normalize(text): String       â”‚         â”‚ + encode(tokens): InputIds  â”‚
â”‚ + spellCheck(text): String      â”‚         â”‚ + decode(ids): String       â”‚
â”‚ + translate(text, lang): String â”‚         â”‚ + createAttentionMask(): [] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Tokens                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - inputIds: int[]               â”‚
â”‚ - attentionMask: int[]          â”‚
â”‚ - tokenTypeIds: int[]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + getInputIds(): int[]          â”‚
â”‚ + getPaddingLength(): int       â”‚
â”‚ + toBatch(): BatchTokens        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TensorFlowClient              â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚     BERTModel               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - serverUrl: String             â”‚         â”‚ - hiddenSize: int = 768     â”‚
â”‚ - modelName: String = "bert"    â”‚         â”‚ - numLayers: int = 12       â”‚
â”‚ - timeout: Duration             â”‚         â”‚ - numAttentionHeads: int=12 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + encode(tokens): Embeddings    â”‚         â”‚ + forward(ids, mask): Emb   â”‚
â”‚ + getEmbeddings(text): Vector   â”‚         â”‚ + getPooledOutput(): Tensor â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ + getSequenceOutput(): Tensorâ”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ClassificationHead            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - dense1: Dense(768 â†’ 256)      â”‚
â”‚ - dropout: Dropout(0.3)         â”‚
â”‚ - dense2: Dense(256 â†’ classes)  â”‚
â”‚ - activation: Softmax           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + classify(embeddings): Probs   â”‚
â”‚ + train(X, y): void             â”‚
â”‚ + predict(embeddings): Probs    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DiseaseClassifier             â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚   DiseaseDatabase           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - classificationHead: Head      â”‚         â”‚ - connection: PostgreSQL    â”‚
â”‚ - diseaseDB: DiseaseDatabase    â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - threshold: float = 0.1        â”‚         â”‚ + getDiseaseByClass(id): Diseaseâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚ + searchBySymptoms(symp): []â”‚
â”‚ + classify(embeddings): Results â”‚         â”‚ + getAllDiseases(): List    â”‚
â”‚ + topK(probs, k): List          â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ExplainabilityService         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - shapExplainer: SHAPExplainer  â”‚
â”‚ - limeExplainer: LIMEExplainer  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + explain(text, pred): Explanationâ”‚
â”‚ + getFeatureImportance(): Map   â”‚
â”‚ + visualize(): Image            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    AnalysisResult               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - id: UUID                      â”‚
â”‚ - predictions: List<Disease>    â”‚
â”‚ - confidenceScores: float[]     â”‚
â”‚ - explanation: Explanation      â”‚
â”‚ - processedText: String         â”‚
â”‚ - timestamp: Timestamp          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + getTopPrediction(): Disease   â”‚
â”‚ + toJSON(): String              â”‚
â”‚ + isHighConfidence(): boolean   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Disease                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - id: int                       â”‚
â”‚ - name: String                  â”‚
â”‚ - icd10Code: String             â”‚
â”‚ - description: String           â”‚
â”‚ - symptoms: List<String>        â”‚
â”‚ - probability: float            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + toString(): String            â”‚
â”‚ + matchesSymptoms(symp): bool   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹:**
- **Pipeline:** TextPreprocessor â†’ Tokenizer â†’ BERT â†’ Classifier
- **Strategy:** Ğ Ğ°Ğ·Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ (SHAP/LIME)
- **Repository:** DiseaseDatabase Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸Ñ

---

### 5. State Diagram (Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹)

**ĞĞ±ÑŠĞµĞºÑ‚:** Text Analysis Task

```
          [Text received]
                 â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â—â”€â”€â”€>â”‚  Queued  â”‚
           â”‚(Ğ’ Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ¸)â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ consumer picks up
                 â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚Preprocessing â”‚
           â”‚(ĞÑ‡Ğ¸ÑÑ‚ĞºĞ°)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
            â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
            â”‚    â”‚    â”‚
    invalid â”‚    â”‚    â”‚ valid
        â”Œâ”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”
        â”‚        â”‚        â”‚
        â†“        â†“        â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Invalid â”‚ â”‚ Tokenizing   â”‚
   â”‚(ĞÑˆĞ¸Ğ±ĞºĞ°)â”‚ â”‚(Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ tokens ready
                     â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Encoding   â”‚
               â”‚(BERT ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ)â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
                â”‚    â”‚    â”‚
       timeout  â”‚    â”‚    â”‚ success
            â”Œâ”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”
            â”‚        â”‚        â”‚
            â†“        â†“        â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚Timeout â”‚ â”‚Classifying   â”‚
       â”‚(Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚)â”‚ â”‚(ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ)â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ classified
                       â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Explaining  â”‚
                 â”‚(Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                  â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
                  â”‚    â”‚    â”‚
                  â”‚    â”‚    â”‚
                  â†“    â†“    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Caching    â”‚ â”‚   Saving     â”‚
            â”‚(ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ) â”‚ â”‚ (Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚Completed â”‚
                     â”‚(Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
                           â—
```

**Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ:**
1. **Queued:** Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ² RabbitMQ
2. **Preprocessing:** ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
3. **Tokenizing:** Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· BERT Tokenizer
4. **Encoding:** ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ embeddings Ğ¾Ñ‚ BERT
5. **Classifying:** ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸Ğ¹
6. **Explaining:** Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ (SHAP)
7. **Caching:** Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Redis
8. **Saving:** Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² PostgreSQL
9. **Completed:** Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°
10. **Invalid/Timeout:** ĞÑˆĞ¸Ğ±ĞºĞ¸

**ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹:**
- `invalid text` â†’ Invalid
- `BERT timeout` â†’ Timeout (retry with exponential backoff)
- `low confidence` â†’ Request human review

---

### 6. Component Diagram (Ğ”Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Text Analysis Service                             â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                      â”‚       â”‚                  â”‚       â”‚
â”‚  â”‚  MessageConsumer     â”‚â”€â”€â”€â”€â”€â”€>â”‚AnalysisOrchestrator     â”‚
â”‚  â”‚   (RabbitMQ)         â”‚triggers                  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â”‚                 â”‚
â”‚                                           â”‚ orchestrates    â”‚
â”‚                                           â†“                 â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                         â”‚  NLP Pipeline               â”‚    â”‚
â”‚                         â”‚                              â”‚    â”‚
â”‚                         â”‚  - TextPreprocessor          â”‚    â”‚
â”‚                         â”‚  - BERTTokenizer             â”‚    â”‚
â”‚                         â”‚  - TensorFlowClient          â”‚    â”‚
â”‚                         â”‚  - DiseaseClassifier         â”‚    â”‚
â”‚                         â”‚  - ExplainabilityService     â”‚    â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                        â”‚
                    â”‚ uses                   â”‚ uses
                    â†“                        â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                        â”‚   â”‚                     â”‚
     â”‚  TensorFlow Serving    â”‚   â”‚   HuggingFace       â”‚
     â”‚    (gRPC Server)       â”‚   â”‚   Transformers      â”‚
     â”‚                        â”‚   â”‚   (Python Library)  â”‚
     â”‚  - BERT Model          â”‚   â”‚                     â”‚
     â”‚  - bert-base-uncased   â”‚   â”‚  - Tokenizers       â”‚
     â”‚  + Classification Head â”‚   â”‚  - Model loading    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Medical Knowledge Components                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                      â”‚       â”‚                  â”‚       â”‚
â”‚  â”‚ DiseaseDatabase      â”‚       â”‚ MedicalDictionaryâ”‚       â”‚
â”‚  â”‚ (PostgreSQL)         â”‚       â”‚ (JSON/Redis)     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                               â”‚                 â”‚
â”‚           â”‚ queries                       â”‚ validates       â”‚
â”‚           â†“                               â†“                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Disease Ontology                         â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  - ICD-10 codes                                  â”‚       â”‚
â”‚  â”‚  - Symptom mappings                              â”‚       â”‚
â”‚  â”‚  - Disease relationships                         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Explainability Components                         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                      â”‚       â”‚                  â”‚       â”‚
â”‚  â”‚  SHAPExplainer       â”‚       â”‚  LIMEExplainer   â”‚       â”‚
â”‚  â”‚  (Python Library)    â”‚       â”‚  (Python Library)â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                               â”‚                 â”‚
â”‚           â”‚ generates                     â”‚ generates       â”‚
â”‚           â†“                               â†“                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Explanation Visualizer                   â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  - Feature importance plots                      â”‚       â”‚
â”‚  â”‚  - Token highlighting                            â”‚       â”‚
â”‚  â”‚  - Confidence intervals                          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Storage & Cache                                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                  â”‚           â”‚                  â”‚       â”‚
â”‚  â”‚  CacheService    â”‚           â”‚ ResultRepository â”‚       â”‚
â”‚  â”‚   (Redis)        â”‚           â”‚  (PostgreSQL)    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑÑ‹:**
- `gRPC`: BERT model API
- `REST API`: Disease database queries
- `AMQP`: RabbitMQ messaging
- `Python API`: HuggingFace transformers

**Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğµ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸:**
- HuggingFace Transformers (BERT)
- SHAP (explainability)
- LIME (local explanations)
- SpaCy (NER Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ²)

---

## Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸

- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [BioBERT Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½Ñ‹](https://arxiv.org/abs/1901.08746)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)
- Â«Natural Language Processing with TransformersÂ» Lewis Tunstall

