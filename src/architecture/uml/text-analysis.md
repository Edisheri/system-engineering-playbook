# UML –î–∏–∞–≥—Ä–∞–º–º—ã: –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞

## –§—É–Ω–∫—Ü–∏—è 4: –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤ (BERT)

### 1. Use Case Diagram (–î–∏–∞–≥—Ä–∞–º–º–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)

```mermaid
graph TB
    subgraph "Actors"
        MLService[ü§ñ ML Service]
        Doctor[üë®‚Äç‚öïÔ∏è –í—Ä–∞—á]
        MLEngineer[üë®‚Äçüíª ML Engineer]
    end
    
    subgraph "Use Cases"
        Tokenize[–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å–∏–º–ø—Ç–æ–º–æ–≤]
        BERTAnalysis[BERT-–∞–Ω–∞–ª–∏–∑ —Å–∏–º–ø—Ç–æ–º–æ–≤]
        Validate[–í–∞–ª–∏–¥–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏]
        FineTune[Fine-tuning BERT –º–æ–¥–µ–ª–∏]
    end
    
    MLService --> Tokenize
    MLService --> BERTAnalysis
    Doctor --> Validate
    MLEngineer --> FineTune
    Validate -.->|extends| BERTAnalysis
    
    style MLService fill:#67c23a,stroke:#4a9428,stroke-width:2px
    style Doctor fill:#67c23a,stroke:#4a9428,stroke-width:2px
    style MLEngineer fill:#67c23a,stroke:#4a9428,stroke-width:2px
    style Tokenize fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style BERTAnalysis fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style Validate fill:#9966ff,stroke:#7744cc,stroke-width:2px,color:#fff
    style FineTune fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
```

**–ê–∫—Ç—ë—Ä—ã:**
- **ML Service** (—Å–∏—Å—Ç–µ–º–∞)
- **–í—Ä–∞—á** (Doctor)
- **ML Engineer** (–∏–Ω–∂–µ–Ω–µ—Ä –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è)

**–í–∞—Ä–∏–∞–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
1. **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å–∏–º–ø—Ç–æ–º–æ–≤**
   - –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–∫—Ç—ë—Ä: ML Service
   - –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏—è: –¢–µ–∫—Å—Ç —Å–∏–º–ø—Ç–æ–º–æ–≤ –ø–æ–ª—É—á–µ–Ω
   - –ü–æ—Å—Ç—É—Å–ª–æ–≤–∏—è: –¢–æ–∫–µ–Ω—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è BERT
   
2. **BERT-–∞–Ω–∞–ª–∏–∑ —Å–∏–º–ø—Ç–æ–º–æ–≤**
   - –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–∫—Ç—ë—Ä: ML Service
   - –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏—è: –¢–æ–∫–µ–Ω—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã
   - –ü–æ—Å—Ç—É—Å–ª–æ–≤–∏—è: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –ø–æ–ª—É—á–µ–Ω—ã
   
3. **–í–∞–ª–∏–¥–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏**
   - –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–∫—Ç—ë—Ä: –í—Ä–∞—á
   - –°–≤—è–∑—å: `<<extend>>` –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
   
4. **Fine-tuning BERT –º–æ–¥–µ–ª–∏**
   - –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–∫—Ç—ë—Ä: ML Engineer
   - –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏—è: –ù–æ–≤—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
   - –ü–æ—Å—Ç—É—Å–ª–æ–≤–∏—è: –ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞

**–°–≤—è–∑–∏:**
- `<<include>>`: –ê–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é
- `<<extend>>`: Spell-check —Ä–∞—Å—à–∏—Ä—è–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é

---

### 2. Activity Diagram (–î–∏–∞–≥—Ä–∞–º–º–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π)

```mermaid
flowchart TD
    Start([–ù–∞—á–∞–ª–æ: Text from RabbitMQ])
    
    A[–ü–æ–ª—É—á–∏—Ç—å symptom_text –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è]
    B{–¢–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º?}
    C[–ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π Google Translate API]
    D[–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ lowercase, —É–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤]
    E[–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤]
    F{–¢–µ—Ä–º–∏–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã?}
    G[–ö–æ—Ä—Ä–µ–∫—Ü–∏—è —á–µ—Ä–µ–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å]
    
    H[–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ BERT Tokenizer]
    I[–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ CLS, SEP]
    J[Padding –¥–æ max_length=128]
    K[–°–æ–∑–¥–∞–Ω–∏–µ attention_mask]
    L[–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ input_ids]
    
    M[BERT Encoding]
    N[Named Entity Recognition]
    O[–ü–æ–ª—É—á–µ–Ω–∏–µ embeddings]
    P[–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–∏–º–ø—Ç–æ–º–æ–≤]
    Q[–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π]
    R[–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    S[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Redis TTL=1h]
    T[–û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –æ—á–µ—Ä–µ–¥—å]
    End([–ö–æ–Ω–µ—Ü])
    
    Start --> A
    A --> B
    B -->|–ù–µ—Ç| C
    C --> D
    B -->|–î–∞| D
    D --> E
    E --> F
    F -->|–ù–µ—Ç| G
    G --> H
    F -->|–î–∞| H
    
    H --> I
    H --> J
    I --> K
    J --> L
    K --> L
    
    L --> M
    L --> N
    M --> O
    N --> Q
    O --> P
    Q --> R
    P --> R
    R --> S
    S --> T
    T --> End
    
    style Start fill:#67c23a,stroke:#4a9428,stroke-width:3px
    style End fill:#f56c6c,stroke:#c94545,stroke-width:3px
    style B fill:#e6a23c,stroke:#b8821e,stroke-width:2px
    style F fill:#e6a23c,stroke:#b8821e,stroke-width:2px
    style H fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style M fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style S fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ BERT –∏ NER
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏

---

### 3. Sequence Diagram (–î–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)

**–£—á–∞—Å—Ç–Ω–∏–∫–∏:**
- RabbitMQ
- TextAnalysisService
- TextPreprocessor
- BERTTokenizer
- TensorFlowServing
- BERTModel
- ClassificationHead
- DiseaseDatabase
- ExplainabilityService
- Redis
- PostgreSQL

```mermaid
sequenceDiagram
    participant R as RabbitMQ
    participant T as TextAnalysisService
    participant P as TextPreprocessor
    participant TK as BERTTokenizer
    participant TF as TensorFlowServing
    participant B as BERTModel
    participant C as ClassificationHead
    participant D as DiseaseDatabase
    participant E as ExplainabilityService
    participant REDIS as Redis
    participant PG as PostgreSQL
    
    R->>T: msg {text}
    T->>P: clean(text)
    P->>P: lowercase, remove special chars
    P->>P: spell check
    P-->>T: cleaned_text
    T->>TK: tokenize(cleaned_text)
    TK->>TK: convert to tokens
    TK->>TK: add [CLS], [SEP]
    TK->>TK: padding to 128
    TK->>TK: create attention_mask
    TK-->>T: token_ids, attention_mask
    T->>TF: predict(token_ids, attention_mask)
    TF->>B: gRPC call
    B->>B: BERT encoding
    B->>C: embeddings
    C->>C: classification
    C-->>TF: logits
    TF-->>T: probabilities
    T->>D: match_diseases(probabilities)
    D-->>T: disease_matches
    T->>E: generate_explanations(text, probabilities)
    E->>E: LIME/SHAP analysis
    E-->>T: explanations
    T->>REDIS: cache(results)
    REDIS-->>T: OK
    T->>PG: save(results, explanations)
    PG-->>T: OK
```

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ pre-trained BERT —Å fine-tuned classification head
- SHAP –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

---

### 4. Class Diagram (–î–∏–∞–≥—Ä–∞–º–º–∞ –∫–ª–∞—Å—Å–æ–≤)

```mermaid
classDiagram
    class TextAnalysisService {
        -TextPreprocessor preprocessor
        -BERTTokenizer tokenizer
        -TensorFlowClient bertClient
        -Classifier classifier
        -Explainability explainer
        +analyzeSymptoms(text) Result
        +processMessage(msg) void
    }
    
    class TextPreprocessor {
        -Dictionary medicalDict
        -Translator translator
        -SpellChecker spellChecker
        +clean(text) String
        +normalize(text) String
        +spellCheck(text) String
        +translate(text, lang) String
    }
    
    class BERTTokenizer {
        -Vocabulary vocab
        -int maxLength
        -String padToken
        +tokenize(text) Tokens
        +encode(tokens) InputIds
        +decode(ids) String
        +createAttentionMask() int[]
    }
    
    class Tokens {
        -int[] inputIds
        -int[] attentionMask
        -int[] tokenTypeIds
        +getInputIds() int[]
        +getPaddingLength() int
        +toBatch() BatchTokens
    }
    
    class TensorFlowClient {
        -String serverUrl
        -String modelName
        -Duration timeout
        +encode(tokens) Embeddings
        +getEmbeddings(text) Vector
    }
    
    class BERTModel {
        -int hiddenSize
        -int numLayers
        -int numAttentionHeads
        +forward(ids, mask) Embeddings
        +getPooledOutput() Tensor
        +getSequenceOutput() Tensor
    }
    
    class ClassificationHead {
        -Dense dense1
        -Dropout dropout
        -Dense dense2
        -Softmax activation
        +classify(embeddings) Probs
        +train(X, y) void
        +predict(embeddings) Probs
    }
    
    class DiseaseClassifier {
        -ClassificationHead classificationHead
        -DiseaseDatabase diseaseDB
        -float threshold
        +classify(embeddings) Results
        +topK(probs, k) List
    }
    
    class DiseaseDatabase {
        -PostgreSQL connection
        +getDiseaseByClass(id) Disease
        +searchBySymptoms(symp) List
        +getAllDiseases() List
    }
    
    class ExplainabilityService {
        -SHAPExplainer shapExplainer
        -LIMEExplainer limeExplainer
        +explain(text, pred) Explanation
        +getFeatureImportance() Map
        +visualize() Image
    }
    
    class AnalysisResult {
        -UUID id
        -List predictions
        -float[] confidenceScores
        -Explanation explanation
        -String processedText
        -Timestamp timestamp
        +getTopPrediction() Disease
        +toJSON() String
        +isHighConfidence() boolean
    }
    
    class Disease {
        -int id
        -String name
        -String icd10Code
        -String description
        -List symptoms
        -float probability
        +toString() String
        +matchesSymptoms(symp) boolean
    }
    
    TextAnalysisService --> TextPreprocessor : uses
    TextAnalysisService --> BERTTokenizer : uses
    TextAnalysisService --> TensorFlowClient : uses
    TextAnalysisService --> DiseaseClassifier : uses
    TextAnalysisService --> ExplainabilityService : uses
    
    BERTTokenizer --> Tokens : creates
    TensorFlowClient --> BERTModel : uses
    DiseaseClassifier --> ClassificationHead : uses
    DiseaseClassifier --> DiseaseDatabase : uses
    DiseaseClassifier --> AnalysisResult : creates
    AnalysisResult --> Disease : contains
```

**–ü–∞—Ç—Ç–µ—Ä–Ω—ã:**
- **Pipeline:** TextPreprocessor ‚Üí Tokenizer ‚Üí BERT ‚Üí Classifier
- **Strategy:** –†–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π (SHAP/LIME)
- **Repository:** DiseaseDatabase –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è

---

### 5. State Diagram (–î–∏–∞–≥—Ä–∞–º–º–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π)

**–û–±—ä–µ–∫—Ç:** Text Analysis Task

```mermaid
stateDiagram-v2
    direction TB
    
    [*] --> Queued : Text received
    Queued --> Preprocessing : consumer picks up
    Preprocessing --> Tokenizing : text valid
    Preprocessing --> Invalid : text invalid
    Tokenizing --> Encoding : tokens ready
    Encoding --> Classifying : BERT success
    Encoding --> Timeout : BERT timeout
    Classifying --> Explaining : classified
    Explaining --> Caching : explanations ready
    Caching --> Completed : saved
    Completed --> [*] : task finished
    
    Invalid --> [*] : error
    Timeout --> Queued : retry
    Timeout --> [*] : max retries
```

**–°–æ—Å—Ç–æ—è–Ω–∏—è:**
1. **Queued:** –ó–∞–¥–∞—á–∞ –≤ RabbitMQ
2. **Preprocessing:** –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
3. **Tokenizing:** –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ BERT Tokenizer
4. **Encoding:** –ü–æ–ª—É—á–µ–Ω–∏–µ embeddings –æ—Ç BERT
5. **Classifying:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π
6. **Explaining:** –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π (SHAP)
7. **Caching:** –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Redis
8. **Saving:** –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ PostgreSQL
9. **Completed:** –ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
10. **Invalid/Timeout:** –û—à–∏–±–∫–∏

**–ü–µ—Ä–µ—Ö–æ–¥—ã:**
- `invalid text` ‚Üí Invalid
- `BERT timeout` ‚Üí Timeout (retry with exponential backoff)
- `low confidence` ‚Üí Request human review

---

### 6. Component Diagram (–î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤)

```mermaid
graph TB
    subgraph "Text Analysis Service"
        MC[MessageConsumer<br/>RabbitMQ]
        AO[AnalysisOrchestrator<br/>Pipeline Controller]
        NLP[NLP Pipeline]
        
        subgraph "NLP Pipeline"
            TP[TextPreprocessor<br/>Clean & Normalize]
            BT[BERTTokenizer<br/>Tokenization]
            TC[TensorFlowClient<br/>gRPC Client]
            DC[DiseaseClassifier<br/>Classification]
            ES[ExplainabilityService<br/>SHAP/LIME]
        end
    end
    
    subgraph "External Services"
        TFS[TensorFlow Serving<br/>gRPC Server<br/>BERT Model]
        HF[HuggingFace<br/>Transformers<br/>Python Library]
        DD[DiseaseDatabase<br/>PostgreSQL]
        REDIS[Redis<br/>Cache Layer]
    end
    
    subgraph "Infrastructure"
        GPU[GPU Cluster<br/>NVIDIA Tesla V100]
        K8S[Kubernetes<br/>Container Orchestration]
    end
    
    MC --> AO
    AO --> NLP
    NLP --> TP
    NLP --> BT
    NLP --> TC
    NLP --> DC
    NLP --> ES
    
    TC --> TFS
    TFS --> GPU
    GPU --> K8S
    BT --> HF
    
    DC --> DD
    ES --> REDIS
    
    style MC fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style AO fill:#4a90e2,stroke:#2e5c8a,stroke-width:2px,color:#fff
    style TFS fill:#ff6f00,stroke:#c43e00,stroke-width:2px,color:#fff
    style GPU fill:#9c27b0,stroke:#6a1b9a,stroke-width:2px,color:#fff
    style DD fill:#336791,stroke:#1a3a5c,stroke-width:2px,color:#fff
    style REDIS fill:#dc382d,stroke:#a02822,stroke-width:2px,color:#fff
```

**–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã:**
- `gRPC`: BERT model API
- `REST API`: Disease database queries
- `AMQP`: RabbitMQ messaging
- `Python API`: HuggingFace transformers

**–í–Ω–µ—à–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:**
- HuggingFace Transformers (BERT)
- SHAP (explainability)
- LIME (local explanations)
- SpaCy (NER –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤)

---

## –ò—Å—Ç–æ—á–Ω–∏–∫–∏

- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [BioBERT –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—ã](https://arxiv.org/abs/1901.08746)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)
- ¬´Natural Language Processing with Transformers¬ª Lewis Tunstall

